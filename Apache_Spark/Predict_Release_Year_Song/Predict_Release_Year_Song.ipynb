{"cells":[{"cell_type":"markdown","source":["We are going to train a linear regression model to predict the release year of a song given a set of audio features. We are using a subset of the [Million Song Dataset](http://labrosa.ee.columbia.edu/millionsong/) from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/YearPredictionMSD) which is hosted on databricks cloud. Before we start coding, check the SparkContext version."],"metadata":{}},{"cell_type":"code","source":["print sc.version\nprint type(sqlContext)\nsqlContext = sqlContext"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["# load data\nfile_name = '/databricks-datasets/cs190/data-001/millionsong.txt'\nraw_data_df = sqlContext.read.load(file_name, 'text')\nprint raw_data_df.show()"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":["In the dataset, for each row the first value is the label and the remaining values are the features."],"metadata":{}},{"cell_type":"code","source":["# view data and data points.\nnum_points = raw_data_df.count()\nprint num_points\nsample_points = raw_data_df.take(5)\nprint sample_points"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":["In MLlib, labeled training instances are stored using the LabeledPoint object. So, we write a function that takes in a DataFrame and parse each row in the DataFrame into a LabeledPoint."],"metadata":{}},{"cell_type":"code","source":["from pyspark.mllib.regression import LabeledPoint\nimport numpy as np"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["from pyspark.sql import functions as sql_functions\n\ndef parse_points(df):\n  \"\"\"Converts a DataFrame of comma separated unicode strings into a DataFrame of LabeledPoints. \n  \n  Args:\n    df: DataFrame where each row is a comma separated unicode string. The first element in the string\n        is the label and the remaining elements are the features.\n  \n  Returns:\n    DataFrame: Each row is converted into a `LabeledPoint`, which consists of a label and\n               features.\n  \"\"\"\n  return (df.select(sql_functions.split(df.value, ',')).alias('value')\n          .map(lambda row: LabeledPoint(float(row[0][0]), list(row[0][1:])))\n          .toDF(['features', 'label']))\n\nparsed_points_df = parse_points(raw_data_df)\nprint(parsed_points_df)\nfirst_point_features = parsed_points_df.first().features\nfirst_point_label = parsed_points_df.first().label\nprint first_point_label, first_point_features\n\nd = len(first_point_features)\nprint(d)"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["# find range of song years and shift labels such that they start from zero.\ncontent_stats = (parsed_points_df\n                 .selectExpr('min(label)', 'max(label)')\n                 .collect())\nprint(content_stats)\nmin_year = content_stats[0][0]\nmax_year = content_stats[0][1]\n\nprint min_year,max_year\n\n# create new dataframe with shifted labels.\nparsed_data_df = (parsed_points_df.select(parsed_points_df.features, parsed_points_df.label - min_year)\n                  .withColumnRenamed('(label - ' + str(min_year) + ')', 'label'))\n\nprint parsed_data_df.first()"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":["Now lets split the dataset into training, validation and test sets. Once that is done we cache each of these datasets because we will be accessing those multiple times."],"metadata":{}},{"cell_type":"code","source":["# split and cache the datasets.\nweights = [.8,.1,.1]\nseed= 23\nparsed_train_data_df, parsed_val_data_df, parsed_test_data_df = parsed_data_df.randomSplit(weights, seed)\nparsed_train_data_df.cache()\nparsed_val_data_df.cache()\nparsed_test_data_df.cache()\nn_train = parsed_train_data_df.count()\nn_val = parsed_val_data_df.count()\nn_test = parsed_test_data_df.count()\n\nprint n_train, n_val, n_test, n_train+n_val+n_test\nprint parsed_data_df.count()"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":["Baseline model is one where we always make the same prediction independent of the given data point, using the average label in the training set as the constant prediction value. Lets compute the average song year for the training set."],"metadata":{}},{"cell_type":"code","source":["# calculate average label.\naverage_train_year = (parsed_train_data_df\n                     .selectExpr('avg(label)').first()[0])\nprint average_train_year"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":["We will use root mean squared error (RMSE) for evaluation purposes. We will write a function to calculate the root mean squared error of a given dataset."],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.evaluation import RegressionEvaluator\n\nevaluator = RegressionEvaluator()\n\ndef calc_RMSE(dataset):\n  \"\"\" Calculates root mean squared error for a dataset of (prediction, label) tuples.\n  \n  Args:\n    dataset (Dataframe of (float, float)): A Dataframe consisting of (prediction, label) tuples.\n  \n  Returns:\n    float: The square root of the mean of the squared errors.\n  \"\"\"\n  return evaluator.evaluate(dataset)"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":["# lets test the function.\npreds_labels = [(1.,2.), (2.,2.), (2.,3.)]\npreds_labels_df = sqlContext.createDataFrame(preds_labels, [\"prediction\", \"label\"])\n\npred_RMSE = calc_RMSE(preds_labels_df)\n# RMSE = sqrt[((1-2)^2 + (2-2)^2 + (2-3)^2) / 3] = 0.81\nprint pred_RMSE"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":["Lets calcuate the training, validation and test RMSE of our baseline model. To do this, we first create DataFrame of (prediction, label) tuples for each dataset and then call calc_RMSE()."],"metadata":{}},{"cell_type":"code","source":["preds_labels_train = parsed_train_data_df.map(lambda x : (average_train_year, x.label))\npreds_labels_train_df = sqlContext.createDataFrame(preds_labels_train, [\"prediction\", \"label\"])\nrmse_train_base = calc_RMSE(preds_labels_train_df)\n\npreds_labels_val = parsed_val_data_df.map(lambda x : (average_train_year, x.label))\npreds_labels_val_df = sqlContext.createDataFrame(preds_labels_val, [\"prediction\", \"label\"])\nrmse_val_base = calc_RMSE(preds_labels_val_df)\n\npreds_labels_test = parsed_test_data_df.map(lambda x : (average_train_year, x.label))\npreds_labels_test_df = sqlContext.createDataFrame(preds_labels_test, [\"prediction\", \"label\"])\nrmse_test_base = calc_RMSE(preds_labels_test_df)\n\nprint 'Baseline Train RMSE = {0:.3f}'.format(rmse_train_base)\nprint 'Baseline Validation RMSE = {0:.3f}'.format(rmse_val_base)\nprint 'Baseline Test RMSE = {0:.3f}'.format(rmse_test_base)"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":["Now let's see if we can do better via linear regression, training a model via gradient descent (we'll omit the intercept for now). Recall that the gradient descent update for linear regression is:\n\\\\[ \\scriptsize \\mathbf{w}_{i+1} = \\mathbf{w}_i - \\alpha_i \\sum_j (\\mathbf{w}_i^\\top\\mathbf{x}_j  - y_j) \\mathbf{x}_j \\,.\\\\]\nwhere \\\\( \\scriptsize i \\\\) is the iteration number of the gradient descent algorithm, and \\\\( \\scriptsize j \\\\) identifies the observation.\n\nFirst, we implement a function that computes the summand for this update, i.e., the summand equals \\\\( \\scriptsize (\\mathbf{w}^\\top \\mathbf{x} - y) \\mathbf{x} \\, ,\\\\) and test out this function on two examples."],"metadata":{}},{"cell_type":"code","source":["from pyspark.mllib.linalg import DenseVector\n\ndef gradient_summand(weights, lp):\n  \"\"\"Calculates the gradient summand for a given weight and LabeledPoint.\n  \n  Args:\n    weights(DenseVector): An array of model weights(betas).\n    lp(LabeledPoint): The LabeledPoint for a single observation.\n  \n  Returns:\n    DenseVector: An array of values the same length as weights. The gradient summand.\n  \"\"\"\n  gradient_summand = ((weights.transpose().dot(lp.features)) - lp.label) * (lp.features)\n  return gradient_summand"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"code","source":["# test gradient summand function.\n\nexample_weights = DenseVector([1,1,1])\nexample_lp = LabeledPoint(3.0, [2, 3, 4])\nsummand_example = gradient_summand(example_weights, example_lp)\nprint summand_example"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":["Next, implement a `get_labeled_predictions` function that takes in weights and an observation's `LabeledPoint` and returns a _(prediction, label)_ tuple. We can predict by computing the dot product between weights and an observation's features."],"metadata":{}},{"cell_type":"code","source":["def get_labeled_prediction(weights, observation):\n  \"\"\"Calculates predictions and returns a (prediction, label) tuple.\n  \n  Args:\n    weights: an array with one weight for each feature in data.\n    observation(LabeledPoint): A LabeledPoint that contain the correct label and the feature for data point.\n  \n  Returns:\n    tuple: A (prediction, label) tuple.\n  \"\"\"\n  predictions = weights.dot(observation.features)\n  label = observation.label\n  return(float(predictions), float(label))"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"code","source":["# test get_labeled_predictions\n\nweights = np.array([1.0, 1.5])\nprediction_example = sc.parallelize([LabeledPoint(2, np.array([.5, 1.0])),\n                                     LabeledPoint(1, np.array([.5, .5]))])\npreds_and_labels_example = prediction_example.map(lambda lp:get_labeled_predictions(weights, lp))\nprint preds_and_labels_example.collect()"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"markdown","source":["Next we implement a gradient descent function for linear regression."],"metadata":{}},{"cell_type":"code","source":["def linreg_gradient_descent(train_data, num_iters):\n  \"\"\"Calculates the weights and error for a linear regression model trained with gradient descent.\n  \n  Args:\n    train_data: labeled data for use in training the model.\n    num_iters: number of iterations of gradient descent to perform.\n  \n  Returns:\n    (np.ndarray, np.ndarray): A tuple of (weights, training_errors)\n  \"\"\"\n  # The length of the training data\n  n = train_data.count()\n  # The number of features in the training data\n  d = len(train_data.first().features)\n  w = np.zeros(d)\n  alpha = 1.0\n  error_train = np.zeros(num_iters)\n  for i in range(num_iters):\n    preds_and_labels_train = train_data.map(lambda lp: get_labeled_prediction(w, lp))\n    preds_and_labels_train_df = sqlContext.createDataFrame(preds_and_labels_train, [\"prediction\", \"label\"])\n    error_train[i] = calc_RMSE(preds_and_labels_train_df)\n    \n    gradient = train_data.map(lambda lp: gradient_summand(w, lp)).sum()\n    # Update the weights\n    alpha_i = alpha / (n * np.sqrt(i+1))\n    w -= alpha_i*gradient\n  return w, error_train"],"metadata":{},"outputs":[],"execution_count":26},{"cell_type":"code","source":["# test linreg_gradient_descent\nexample_n = 10\nexample_d = 3\nexample_data = (sc\n                .parallelize(parsed_train_data_df.take(example_n))\n                .map(lambda lp: LabeledPoint(lp.label, lp.features[0:example_d])))\nprint example_data.take(2)\nexample_num_iters = 5\nexample_weights, example_error_train = linreg_gradient_descent(example_data, example_num_iters)\nprint example_weights"],"metadata":{},"outputs":[],"execution_count":27},{"cell_type":"markdown","source":["Lets train a linear regression model on all our training data and evaluate its accuracy on the validation set."],"metadata":{}},{"cell_type":"code","source":["num_iters = 50\nweights_LR0, error_train_LR0 = linreg_gradient_descent(parsed_train_data_df, num_iters)\npreds_and_labels = (parsed_val_data_df\n                    .map(lambda lp: get_labeled_prediction(weights_LR0, lp)))\npreds_and_labels_df = sqlContext.createDataFrame(preds_and_labels, [\"prediction\", \"label\"])\nrmse_val_LR0 = calc_RMSE(preds_and_labels_df)\n\nprint 'Validation RMSE:\\n\\tBaseline = {0:.3f}\\n\\tLR0 = {1:.3f}'.format(rmse_val_base,\n                                                                       rmse_val_LR0)"],"metadata":{},"outputs":[],"execution_count":29},{"cell_type":"markdown","source":["We have done better than the baseline model, but now we see if we can do better by adding an intercept using regularization and training more iterations. We use LinearRegression to train model with elastic net regularization and an intercept."],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.regression import LinearRegression\n\n# values to use when training the linear regression model\nnum_iters = 500\nreg = 1e-1\nalpha = .2\nuse_intercept = True\n\n# train a Linear Regression model\nlin_reg = LinearRegression(maxIter=num_iters, regParam=reg, elasticNetParam=alpha, fitIntercept=use_intercept)\nfirst_model = lin_reg.fit(parsed_train_data_df)\n\n# coeffsLR1 stores the model coefficients; interceptLR1 stores the model intercept\ncoeffs_LR1 = first_model.coefficients\nintercept_LR1 = first_model.intercept\nprint coeffs_LR1, intercept_LR1"],"metadata":{},"outputs":[],"execution_count":31},{"cell_type":"code","source":["# make predictions on the parsed_train_data_df\nsample_prediction = first_model.transform(parsed_train_data_df)\ndisplay(sample_prediction)"],"metadata":{},"outputs":[],"execution_count":32},{"cell_type":"code","source":["# evaluate the accuracy of the model on the validation set.\nval_pred_df = first_model.transform(parsed_val_data_df)\nrmse_val_LR1 = calc_RMSE(val_pred_df)\n\nprint ('Validation RMSE:\\n\\tBaseline = {0:.3f}\\n\\tLR0 = {1:.3f}\\n\\tLR1 = {2:.3f}').format(rmse_val_base, rmse_val_LR0, rmse_val_LR1)"],"metadata":{},"outputs":[],"execution_count":33},{"cell_type":"markdown","source":["We're already outperforming the baseline on the validation set by almost 3 years on average, but let's see if we can do better. We perform grid search to find a good regularization parameter"],"metadata":{}},{"cell_type":"code","source":["best_RMSE = rmse_val_LR1\nbest_reg_param = reg\nbest_model = first_model\n\nnum_iters = 500  # iterations\nalpha = .2  # elasticNetParam\nuse_intercept = True  # intercept\n\nfor reg in [1e-10, 1e-5, 1.0]:\n    lin_reg = LinearRegression(maxIter=num_iters, regParam=reg, elasticNetParam=alpha, fitIntercept=use_intercept)\n    model = lin_reg.fit(parsed_train_data_df)\n    val_pred_df = model.transform(parsed_val_data_df)\n\n    rmse_val_grid = calc_RMSE(val_pred_df)\n    print rmse_val_grid\n\n    if rmse_val_grid < best_RMSE:\n        best_RMSE = rmse_val_grid\n        best_reg_param = reg\n        best_model = model\n\nrmse_val_LR_grid = best_RMSE\n\nprint ('Validation RMSE:\\n\\tBaseline = {0:.3f}\\n\\tLR0 = {1:.3f}\\n\\tLR1 = {2:.3f}\\n' +\n       '\\tLRGrid = {3:.3f}').format(rmse_val_base, rmse_val_LR0, rmse_val_LR1, rmse_val_LR_grid)"],"metadata":{},"outputs":[],"execution_count":35},{"cell_type":"markdown","source":["So far, we've used the features as they were provided.  Now, we will add features that capture the two-way interactions between our existing features."],"metadata":{}},{"cell_type":"code","source":["import itertools\n\ndef two_way_interactions(lp):\n    \"\"\"Creates a new `LabeledPoint` that includes two-way interactions.\n    \n    Args:\n        lp (LabeledPoint): The label and features for this observation.\n\n    Returns:\n        LabeledPoint: The new `LabeledPoint` should have the same label as `lp`.  Its features\n            should include the features from `lp` followed by the two-way interaction features.\n    \"\"\"\n    combinations = itertools.product(lp.features, repeat = 2)\n    list_combs = []\n    final_list = [lp.label]\n    for y in lp.features:\n      list_combs.append(y)\n    for x in combinations:\n      prods = np.prod(np.array(x))\n      list_combs.append(prods)\n    final_list.append(list_combs)\n    lbp = LabeledPoint(label=final_list[0], features=final_list[1])\n    return lbp\n\nprint two_way_interactions(LabeledPoint(0.0, [2, 3]))"],"metadata":{},"outputs":[],"execution_count":37},{"cell_type":"code","source":["# Transform the existing train, validation, and test sets to include two-way interactions.\ntrain_data_interact_df = parsed_train_data_df.map(two_way_interactions).toDF()\nval_data_interact_df = parsed_val_data_df.map(two_way_interactions).toDF()\ntest_data_interact_df = parsed_test_data_df.map(two_way_interactions).toDF()\na=parsed_val_data_df.rdd.first()\nprint a.features\nf=two_way_interactions(LabeledPoint(a.label, a.features)).features\nprint sum(f)"],"metadata":{},"outputs":[],"execution_count":38},{"cell_type":"code","source":["# lets build the interaction model\nnum_iters = 500\nreg = 1e-10\nalpha = .2\nuse_intercept = True\n\nlin_reg = LinearRegression(maxIter=num_iters, regParam=reg, elasticNetParam=alpha, fitIntercept=use_intercept)\nmodel_interact = lin_reg.fit(train_data_interact_df)\npreds_and_labels_interact_df = model_interact.transform(val_data_interact_df)\nrmse_val_interact = calc_RMSE(preds_and_labels_interact_df)\n\nprint ('Validation RMSE:\\n\\tBaseline = {0:.3f}\\n\\tLR0 = {1:.3f}\\n\\tLR1 = {2:.3f}\\n\\tLRGrid = ' +\n       '{3:.3f}\\n\\tLRInteract = {4:.3f}').format(rmse_val_base, rmse_val_LR0, rmse_val_LR1,\n                                                 rmse_val_LR_grid, rmse_val_interact)"],"metadata":{},"outputs":[],"execution_count":39},{"cell_type":"code","source":["# evaluate interaction model on test data.\npreds_and_labels_test_df = model_interact.transform(test_data_interact_df)\nrmse_test_interact = calc_RMSE(preds_and_labels_test_df)\n\nprint ('Test RMSE:\\n\\tBaseline = {0:.3f}\\n\\tLRInteract = {1:.3f}'\n       .format(rmse_test_base, rmse_test_interact))"],"metadata":{},"outputs":[],"execution_count":40},{"cell_type":"markdown","source":["Our final step is to create the interaction model using a [Pipeline](http://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.Pipeline)."],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml import Pipeline\nfrom pyspark.ml.feature import PolynomialExpansion\n\nnum_iters = 500\nreg = 1e-10\nalpha = .2\nuse_intercept = True\n\npolynomial_expansion = PolynomialExpansion(degree=2, inputCol='features', outputCol='polyFeatures')\nlinear_regression = LinearRegression(maxIter=num_iters, regParam=reg, elasticNetParam=alpha,\n                                     fitIntercept=use_intercept, featuresCol='polyFeatures')\n\npipeline = Pipeline(stages=[polynomial_expansion, linear_regression])\npipeline_model = pipeline.fit(parsed_train_data_df)\n\npredictions_df = pipeline_model.transform(parsed_test_data_df)\n\nevaluator = RegressionEvaluator()\nrmse_test_pipeline = evaluator.evaluate(predictions_df, {evaluator.metricName: \"rmse\"})\nprint('RMSE for test data set using pipelines: {0:.3f}'.format(rmse_test_pipeline))"],"metadata":{},"outputs":[],"execution_count":42}],"metadata":{"name":"Predict_Release_Year_Song","notebookId":4429158020653323},"nbformat":4,"nbformat_minor":0}
